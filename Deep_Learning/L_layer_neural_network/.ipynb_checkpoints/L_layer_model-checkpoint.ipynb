{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "#%run dnn_utils.ipynb\n",
    "#%run init_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each\n",
    "    layer in our network ,→\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\",\n",
    "    \"b1\", ..., \"WL\", \"bL\": ,→\n",
    "    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1]) * 0.01 \n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l],layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of\n",
    "    previous layer, number of examples) ,→\n",
    "    W -- weights matrix: numpy array of shape (size of current layer,\n",
    "    size of previous layer) ,→\n",
    "    b -- bias vector, numpy array of shape (size of the current layer,\n",
    "    1) ,→\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called\n",
    "    pre-activation parameter ,→\n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored\n",
    "    for computing the backward pass efficiently ,→\n",
    "    \"\"\"\n",
    "    Z = np.dot(W,A)+b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of\n",
    "    previous layer, number of examples) ,→\n",
    "    W -- weights matrix: numpy array of shape (size of current layer,\n",
    "    size of previous layer) ,→\n",
    "    b -- bias vector, numpy array of shape (size of the current layer,\n",
    "    1) ,→\n",
    "    activation -- the activation to be used in this layer, stored as a\n",
    "    text string: \"sigmoid\" or \"relu\" ,→\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the\n",
    "    post-activation value ,→\n",
    "    cache -- a python dictionary containing \"linear_cache\" and\n",
    "    \"activation_cache\"; ,→\n",
    "    stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "# Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the\n",
    "    [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation ,→\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "    every cache of linear_relu_forward() (there are L-1 of\n",
    "    them, indexed from 0 to L-2) ,→\n",
    "    the cache of linear_sigmoid_forward() (there is one,\n",
    "    indexed L-1) ,→\n",
    "    \"\"\"\n",
    "    caches = []\n",
    "    A = X \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\"list. ,→\n",
    "    for l in range(1, L):\n",
    "        \n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' +str(l)], parameters['b' + str(l)], activation =\"relu\") \n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)],parameters['b' + str(L)], activation = \"sigmoid\") \n",
    "    caches.append(cache)\n",
    "\n",
    "\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions,\n",
    "    shape (1, number of examples) ,→\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1\n",
    "    if cat), shape (1, number of examples) ,→\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    # Compute loss from aL and y.\n",
    "    cost = -(np.dot(Y,np.log(AL.T))+np.dot(1-Y,np.log(1-AL).T))/m\n",
    "    \n",
    "    cost = np.squeeze(cost) # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17). \n",
    "    assert(cost.shape == ())\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single\n",
    "    layer (layer l) ,→\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of\n",
    "    current layer l) ,→\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward\n",
    "    propagation in the current layer ,→\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of\n",
    "    the previous layer l-1), same shape as A_prev ,→\n",
    "    dW -- Gradient of the cost with respect to W (current layer l),\n",
    "    same shape as W ,→\n",
    "    db -- Gradient of the cost with respect to b (current layer l),\n",
    "    same shape as b ,→\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = np.dot(dZ,A_prev.T)/m\n",
    "    db = np.sum(dZ,axis=1,keepdims=True)/m\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION\n",
    "    layer. ,→\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l\n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store\n",
    "    for computing backward propagation efficiently ,→\n",
    "    activation -- the activation to be used in this layer, stored as a\n",
    "    text string: \"sigmoid\" or \"relu\" ,→\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of\n",
    "    the previous layer l-1), same shape as A_prev ,→\n",
    "    dW -- Gradient of the cost with respect to W (current layer l),\n",
    "    same shape as W ,→\n",
    "    db -- Gradient of the cost with respect to b (current layer l),\n",
    "    same shape as b ,→\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "       \n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        \n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1)\n",
    "    -> LINEAR -> SIGMOID group ,→\n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation\n",
    "    (L_model_forward()) ,→\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "    every cache of linear_activation_forward() with \"relu\"\n",
    "    (it's caches[l], for l in range(L-1) i.e l = 0...L-2) ,→\n",
    "    the cache of linear_activation_forward() with \"sigmoid\"\n",
    "    (it's caches[L-1]) ,→\n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "    grads[\"dA\" + str(l)] = ...\n",
    "    grads[\"dW\" + str(l)] = ...\n",
    "    grads[\"db\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1] \n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    # Initializing the backpropagation\n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"] ,→\n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    \n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "    # lth layer: (RELU -> LINEAR) gradients.\n",
    "    # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs:\"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] ,grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+2)],current_cache, \"relu\")\n",
    "       \n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters\n",
    "    grads -- python dictionary containing your gradients, output of\n",
    "    L_model_backward ,→\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters\n",
    "    parameters[\"W\" + str(l)] = ...\n",
    "    76\n",
    "    parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_x_orig.shape[0]\n",
    "m_test = test_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x = image2vec(train_x_orig,test_x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 12288 # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075,num_iterations = 3000, print_cost=False): \n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network:\n",
    "    LINEAR->RELU->LINEAR->SIGMOID. ,→\n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of\n",
    "    shape (1, number of examples) ,→\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100\n",
    "    iterations ,→\n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = [] # to keep track of the cost\n",
    "    m = X.shape[1] # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented ,→\n",
    "\n",
    "    parameters =initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    # Loop (gradient descent)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID.        Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\n",
    "       \n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        \n",
    "        # Compute cost\n",
    "        \n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\"\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2,\"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] todW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        # Update parameters.\n",
    "        \n",
    "        parameters = update_parameters(parameters, grads,learning_rate) \n",
    "   \n",
    "    # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost))) \n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6930497356599888\n",
      "Cost after iteration 100: 0.6464320953428849\n",
      "Cost after iteration 200: 0.6325140647912678\n",
      "Cost after iteration 300: 0.6015024920354665\n",
      "Cost after iteration 400: 0.5601966311605748\n",
      "Cost after iteration 500: 0.515830477276473\n",
      "Cost after iteration 600: 0.4754901313943325\n",
      "Cost after iteration 700: 0.43391631512257495\n",
      "Cost after iteration 800: 0.4007977536203886\n",
      "Cost after iteration 900: 0.35807050113237976\n",
      "Cost after iteration 1000: 0.33942815383664127\n",
      "Cost after iteration 1100: 0.3052753636196264\n",
      "Cost after iteration 1200: 0.2749137728213016\n",
      "Cost after iteration 1300: 0.2468176821061484\n",
      "Cost after iteration 1400: 0.19850735037466108\n",
      "Cost after iteration 1500: 0.17448318112556643\n",
      "Cost after iteration 1600: 0.1708076297809599\n",
      "Cost after iteration 1700: 0.1130652456216474\n",
      "Cost after iteration 1800: 0.09629426845937158\n",
      "Cost after iteration 1900: 0.0834261795972687\n",
      "Cost after iteration 2000: 0.07439078704319084\n",
      "Cost after iteration 2100: 0.06630748132267934\n",
      "Cost after iteration 2200: 0.059193295010381744\n",
      "Cost after iteration 2300: 0.05336140348560556\n",
      "Cost after iteration 2400: 0.04855478562877018\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h,n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009 ,→\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network:\n",
    "    [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px *\n",
    "    num_px * 3) ,→\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of\n",
    "    shape (1, number of examples) ,→\n",
    "    layers_dims -- list containing the input size and each layer size,\n",
    "    of length (number of layers + 1). ,→\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used\n",
    "    to predict. ,→\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    costs = [] # keep track of cost\n",
    "    # Parameters initialization.\n",
    "\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "    # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "    \n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "\n",
    "        # Compute cost.\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        # Backward propagation.\n",
    "\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "\n",
    "        # Update parameters.\n",
    "\n",
    "        parameters = update_parameters(parameters, grads,learning_rate) \n",
    "\n",
    "\n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693148\n",
      "Cost after iteration 100: 0.678011\n",
      "Cost after iteration 200: 0.667600\n",
      "Cost after iteration 300: 0.660422\n",
      "Cost after iteration 400: 0.655458\n",
      "Cost after iteration 500: 0.652013\n",
      "Cost after iteration 600: 0.649616\n",
      "Cost after iteration 700: 0.647942\n",
      "Cost after iteration 800: 0.646770\n",
      "Cost after iteration 900: 0.645947\n",
      "Cost after iteration 1000: 0.645368\n",
      "Cost after iteration 1100: 0.644961\n",
      "Cost after iteration 1200: 0.644673\n",
      "Cost after iteration 1300: 0.644469\n",
      "Cost after iteration 1400: 0.644325\n",
      "Cost after iteration 1500: 0.644223\n",
      "Cost after iteration 1600: 0.644151\n",
      "Cost after iteration 1700: 0.644100\n",
      "Cost after iteration 1800: 0.644063\n",
      "Cost after iteration 1900: 0.644037\n",
      "Cost after iteration 2000: 0.644019\n",
      "Cost after iteration 2100: 0.644006\n",
      "Cost after iteration 2200: 0.643997\n",
      "Cost after iteration 2300: 0.643990\n",
      "Cost after iteration 2400: 0.643985\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims,num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
